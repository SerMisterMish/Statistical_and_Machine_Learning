{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61ae8e69",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-11-23T14:44:15.125751Z",
     "iopub.status.busy": "2025-11-23T14:44:15.125495Z",
     "iopub.status.idle": "2025-11-23T14:44:22.208056Z",
     "shell.execute_reply": "2025-11-23T14:44:22.207332Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 7.087793,
     "end_time": "2025-11-23T14:44:22.209417",
     "exception": false,
     "start_time": "2025-11-23T14:44:15.121624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pretty_midi\r\n",
      "  Downloading pretty_midi-0.2.11.tar.gz (5.6 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from pretty_midi) (1.26.4)\r\n",
      "Collecting mido>=1.1.16 (from pretty_midi)\r\n",
      "  Downloading mido-1.3.3-py3-none-any.whl.metadata (6.4 kB)\r\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from pretty_midi) (1.17.0)\r\n",
      "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from pretty_midi) (6.5.2)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mido>=1.1.16->pretty_midi) (25.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.7.0->pretty_midi) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.7.0->pretty_midi) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.7.0->pretty_midi) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.7.0->pretty_midi) (2025.3.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.7.0->pretty_midi) (2022.3.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.7.0->pretty_midi) (2.4.1)\r\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.7.0->pretty_midi) (2025.3.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.7.0->pretty_midi) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.7.0->pretty_midi) (2022.3.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.7.0->pretty_midi) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.7.0->pretty_midi) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.7.0->pretty_midi) (2024.2.0)\r\n",
      "Downloading mido-1.3.3-py3-none-any.whl (54 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: pretty_midi\r\n",
      "  Building wheel for pretty_midi (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for pretty_midi: filename=pretty_midi-0.2.11-py3-none-any.whl size=5595886 sha256=4fa66efdd6e1f32429ec3d8201f7ccf7fd5bf0d403fd68c1805b2dea0f87d11c\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/09/e6/e6/29223dbea25e71e517b8791bf35cc9a7b872cb2ad284e30181\r\n",
      "Successfully built pretty_midi\r\n",
      "Installing collected packages: mido, pretty_midi\r\n",
      "Successfully installed mido-1.3.3 pretty_midi-0.2.11\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pretty_midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17553e25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T14:44:22.216557Z",
     "iopub.status.busy": "2025-11-23T14:44:22.216077Z",
     "iopub.status.idle": "2025-11-23T14:44:25.910108Z",
     "shell.execute_reply": "2025-11-23T14:44:25.909508Z"
    },
    "papermill": {
     "duration": 3.699014,
     "end_time": "2025-11-23T14:44:25.911535",
     "exception": false,
     "start_time": "2025-11-23T14:44:22.212521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pretty_midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff72ec4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T14:44:25.918488Z",
     "iopub.status.busy": "2025-11-23T14:44:25.917861Z",
     "iopub.status.idle": "2025-11-23T14:44:25.935605Z",
     "shell.execute_reply": "2025-11-23T14:44:25.935067Z"
    },
    "papermill": {
     "duration": 0.022137,
     "end_time": "2025-11-23T14:44:25.936577",
     "exception": false,
     "start_time": "2025-11-23T14:44:25.914440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TIME_STEP = 0.02\n",
    "MAX_TIME_SHIFT = 100\n",
    "MAX_DURATION = 200\n",
    "\n",
    "def find_midi_files(root_dir):\n",
    "    midi_files = []\n",
    "    for dirpath, _, filenames in os.walk(root_dir):\n",
    "        for f in filenames:\n",
    "            if f.lower().endswith(('.mid', '.midi')):\n",
    "                midi_files.append(os.path.join(dirpath, f))\n",
    "    return midi_files\n",
    "\n",
    "def midi_to_notes(path):\n",
    "    pm = pretty_midi.PrettyMIDI(path)\n",
    "\n",
    "    events = []\n",
    "\n",
    "    note_events = []\n",
    "    for inst in pm.instruments:\n",
    "        if inst.is_drum:\n",
    "            continue\n",
    "\n",
    "        for note in inst.notes:\n",
    "            duration = note.end - note.start\n",
    "            note_events.append((note.start, note.pitch, duration))\n",
    "    \n",
    "    note_events.sort(key=lambda x: x[0])\n",
    "    \n",
    "    prev_time = 0.0\n",
    "    i = 0\n",
    "    \n",
    "    while i < len(note_events):\n",
    "        current_start_time = note_events[i][0]\n",
    "        \n",
    "        dt = current_start_time - prev_time\n",
    "        steps = int(dt / TIME_STEP)\n",
    "        while steps > 0:\n",
    "            shift = min(steps, MAX_TIME_SHIFT)\n",
    "            events.append(f\"time_shift_{shift}\")\n",
    "            steps -= shift\n",
    "        \n",
    "        chord_notes = []\n",
    "        while i < len(note_events) and abs(note_events[i][0] - current_start_time) < TIME_STEP / 2:\n",
    "            _, pitch, duration = note_events[i]\n",
    "            chord_notes.append((pitch, duration))\n",
    "            i += 1\n",
    "        \n",
    "        for pitch, duration in chord_notes:\n",
    "            duration_steps = int(duration / TIME_STEP)\n",
    "            duration_steps = min(duration_steps, MAX_DURATION)\n",
    "            duration_steps = max(duration_steps, 1)\n",
    "            \n",
    "            events.append(f\"note_on_{pitch}\")\n",
    "            events.append(f\"duration_{duration_steps}\")\n",
    "        \n",
    "        prev_time = current_start_time\n",
    "\n",
    "    return events\n",
    "\n",
    "def build_vocab(event_lists):\n",
    "    vocab = {\"<pad>\": 0, \"<start>\": 1, \"<end>\": 2}\n",
    "    idx = 3\n",
    "\n",
    "    for events in event_lists:\n",
    "        for e in events:\n",
    "            if e not in vocab:\n",
    "                vocab[e] = idx\n",
    "                idx += 1\n",
    "\n",
    "    return vocab\n",
    "\n",
    "def notes_to_tokens(events, vocab):\n",
    "    return [vocab[\"<start>\"]] + [vocab[e] for e in events if e in vocab] + [vocab[\"<end>\"]]\n",
    "\n",
    "def tokens_to_midi(tokens, vocab, save_path=\"out.mid\"):\n",
    "    inv_vocab = {i: e for e, i in vocab.items()}\n",
    "    pm = pretty_midi.PrettyMIDI()\n",
    "    inst = pretty_midi.Instrument(program=0)\n",
    "    pm.instruments.append(inst)\n",
    "\n",
    "    current_time = 0.0\n",
    "    pending_notes = []\n",
    "\n",
    "    for tok in tokens:\n",
    "        if tok not in inv_vocab:\n",
    "            continue\n",
    "\n",
    "        e = inv_vocab[tok]\n",
    "        \n",
    "        if e in (\"<pad>\", \"<start>\", \"<end>\"):\n",
    "            continue\n",
    "\n",
    "        if e.startswith(\"time_shift_\"):\n",
    "            dt = int(e.split(\"_\")[2]) * TIME_STEP\n",
    "            current_time += dt\n",
    "\n",
    "        elif e.startswith(\"note_on_\"):\n",
    "            pitch = int(e.split(\"_\")[2])\n",
    "            pending_notes.append([pitch, current_time, None])\n",
    "\n",
    "        elif e.startswith(\"duration_\"):\n",
    "            duration_steps = int(e.split(\"_\")[1])\n",
    "            for note in reversed(pending_notes):\n",
    "                if note[2] is None:\n",
    "                    note[2] = duration_steps\n",
    "                    end_time = note[1] + duration_steps * TIME_STEP\n",
    "                    inst.notes.append(pretty_midi.Note(\n",
    "                        velocity=80,\n",
    "                        pitch=note[0],\n",
    "                        start=note[1],\n",
    "                        end=end_time\n",
    "                    ))\n",
    "                    break\n",
    "\n",
    "    pm.write(save_path)\n",
    "\n",
    "class MIDITokenDataset(Dataset):\n",
    "    def __init__(self, token_sequences, seq_len=1024, pad_id=0):\n",
    "        self.data = token_sequences\n",
    "        self.seq_len = seq_len\n",
    "        self.pad_id = pad_id\n",
    "\n",
    "        self.chunks = []\n",
    "        for seq in token_sequences:\n",
    "            if len(seq) <= seq_len + 1:\n",
    "                self.chunks.append((seq, 0, len(seq)))\n",
    "            else:\n",
    "                num_chunks = (len(seq) - seq_len - 1) // (seq_len // 2) + 1\n",
    "                for i in range(num_chunks):\n",
    "                    start = i * (seq_len // 2)\n",
    "                    if start + seq_len + 1 > len(seq):\n",
    "                        start = len(seq) - seq_len - 1\n",
    "                    self.chunks.append((seq, start, start + seq_len + 1))\n",
    "\n",
    "        self.total_tokens = sum(len(x) for x in token_sequences)\n",
    "        print(f\"Loaded dataset with {len(self.data)} files, {self.total_tokens} total tokens\")\n",
    "        print(f\"Created {len(self.chunks)} training chunks\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.chunks)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq, start, end = self.chunks[idx]\n",
    "        chunk = seq[start:end]\n",
    "\n",
    "        if len(chunk) < self.seq_len + 1:\n",
    "            padded = chunk + [self.pad_id] * (self.seq_len + 1 - len(chunk))\n",
    "            inp = padded[:-1]\n",
    "            target = padded[1:]\n",
    "        else:\n",
    "            inp = chunk[:-1]\n",
    "            target = chunk[1:]\n",
    "\n",
    "        return torch.tensor(inp, dtype=torch.long), torch.tensor(target, dtype=torch.long)\n",
    "\n",
    "\n",
    "def collate_batch(batch, pad_id=0):\n",
    "    inps, targets = zip(*batch)\n",
    "\n",
    "    max_len = max(x.size(0) for x in inps)\n",
    "\n",
    "    padded_inps = []\n",
    "    padded_targets = []\n",
    "\n",
    "    for inp, tgt in zip(inps, targets):\n",
    "        pad_len = max_len - inp.size(0)\n",
    "\n",
    "        padded_inps.append(\n",
    "            torch.cat([inp, torch.full((pad_len,), pad_id, dtype=torch.long)])\n",
    "        )\n",
    "        padded_targets.append(\n",
    "            torch.cat([tgt, torch.full((pad_len,), pad_id, dtype=torch.long)])\n",
    "        )\n",
    "\n",
    "    return torch.stack(padded_inps), torch.stack(padded_targets)\n",
    "\n",
    "def create_dataloader(token_sequences, seq_len=512, batch_size=128, pad_id=0, shuffle=True):\n",
    "    dataset = MIDITokenDataset(\n",
    "        token_sequences,\n",
    "        seq_len=seq_len,\n",
    "        pad_id=pad_id,\n",
    "    )\n",
    "\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        collate_fn=lambda b: collate_batch(b, pad_id=pad_id),\n",
    "        drop_last=True,\n",
    "        num_workers=0,\n",
    "    )\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a89b4852",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T14:44:25.942770Z",
     "iopub.status.busy": "2025-11-23T14:44:25.942321Z",
     "iopub.status.idle": "2025-11-23T14:44:46.508430Z",
     "shell.execute_reply": "2025-11-23T14:44:46.507483Z"
    },
    "papermill": {
     "duration": 20.570414,
     "end_time": "2025-11-23T14:44:46.509623",
     "exception": false,
     "start_time": "2025-11-23T14:44:25.939209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдено файлов: 295\n",
      "Обработано файлов: 239\n",
      "Пропущено файлов: 56\n",
      "Размер словаря: 388\n",
      "\n",
      "Всего токенов: 936936\n",
      "Средняя длина последовательности: 3920.23\n",
      "Loaded dataset with 191 files, 772804 total tokens\n",
      "Created 2731 training chunks\n",
      "Loaded dataset with 48 files, 164132 total tokens\n",
      "Created 573 training chunks\n"
     ]
    }
   ],
   "source": [
    "MIDI_DIR = '/kaggle/input/classical-music-midi'\n",
    "MIN_EVENTS = 50\n",
    "MAX_EVENTS = 10000\n",
    "\n",
    "midi_files = find_midi_files(MIDI_DIR)\n",
    "print(f\"Найдено файлов: {len(midi_files)}\")\n",
    "\n",
    "all_notes = []\n",
    "skipped = 0\n",
    "\n",
    "for file in midi_files:\n",
    "    try:\n",
    "        notes = midi_to_notes(file)\n",
    "        \n",
    "        if MIN_EVENTS <= len(notes) <= MAX_EVENTS:\n",
    "            all_notes.append(notes)\n",
    "        else:\n",
    "            skipped += 1\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\nОшибка в {file}: {e}\")\n",
    "        skipped += 1\n",
    "\n",
    "print(f\"Обработано файлов: {len(all_notes)}\")\n",
    "print(f\"Пропущено файлов: {skipped}\")\n",
    "\n",
    "vocab = build_vocab(all_notes)\n",
    "print(f\"Размер словаря: {len(vocab)}\")\n",
    "\n",
    "token_sequences = []\n",
    "for notes in all_notes:\n",
    "    tokens = notes_to_tokens(notes, vocab)\n",
    "    token_sequences.append(tokens)\n",
    "\n",
    "total_tokens = sum(len(seq) for seq in token_sequences)\n",
    "avg_length = total_tokens / len(token_sequences) if token_sequences else 0\n",
    "print(f\"\\nВсего токенов: {total_tokens}\")\n",
    "print(f\"Средняя длина последовательности: {avg_length:.2f}\")\n",
    "\n",
    "SEQ_LEN = 512\n",
    "BATCH_SIZE = 128\n",
    "PAD_ID = vocab[\"<pad>\"]\n",
    "\n",
    "train_loader = create_dataloader(\n",
    "    token_sequences[:int(0.8 * len(token_sequences))],\n",
    "    seq_len=SEQ_LEN,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    pad_id=PAD_ID,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader(\n",
    "    token_sequences[int(0.8 * len(token_sequences)):],\n",
    "    seq_len=SEQ_LEN,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    pad_id=PAD_ID,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1053dd5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-23T14:44:46.516416Z",
     "iopub.status.busy": "2025-11-23T14:44:46.515993Z",
     "iopub.status.idle": "2025-11-23T14:44:46.523442Z",
     "shell.execute_reply": "2025-11-23T14:44:46.522694Z"
    },
    "papermill": {
     "duration": 0.012164,
     "end_time": "2025-11-23T14:44:46.524646",
     "exception": false,
     "start_time": "2025-11-23T14:44:46.512482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MusicGRU(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=256, hidden_dim=512, num_layers=3, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=embed_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        emb = self.embedding(x)\n",
    "        out, hidden = self.gru(emb, hidden)\n",
    "        logits = self.fc(out)\n",
    "        return logits, hidden\n",
    "\n",
    "    def generate(self, start_token, max_len=1024, temperature=1.0, top_p=0.95):\n",
    "        self.eval()\n",
    "\n",
    "        device = next(self.parameters()).device\n",
    "        \n",
    "        tokens = [start_token]\n",
    "        inp = torch.tensor([[start_token]], device=device)\n",
    "        hidden = None\n",
    "\n",
    "        for _ in range(max_len):\n",
    "            logits, hidden = self.forward(inp, hidden)\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "\n",
    "            sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
    "            cumulative_probs = torch.softmax(sorted_logits, dim=-1).cumsum(dim=-1)\n",
    "\n",
    "            cutoff = cumulative_probs > top_p\n",
    "            cutoff[..., 1:] = cutoff[..., :-1]\n",
    "            cutoff[..., 0] = False\n",
    "            sorted_logits[cutoff] = -1e9\n",
    "\n",
    "            probs = torch.softmax(sorted_logits, dim=-1)\n",
    "            next_token = sorted_indices[0, torch.multinomial(probs[0], 1)].item()\n",
    "            \n",
    "            tokens.append(next_token)\n",
    "            inp = torch.tensor([[next_token]], device=device)\n",
    "\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07bc5300",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T14:44:46.531029Z",
     "iopub.status.busy": "2025-11-23T14:44:46.530685Z",
     "iopub.status.idle": "2025-11-23T14:44:47.223114Z",
     "shell.execute_reply": "2025-11-23T14:44:47.222268Z"
    },
    "papermill": {
     "duration": 0.697067,
     "end_time": "2025-11-23T14:44:47.224439",
     "exception": false,
     "start_time": "2025-11-23T14:44:46.527372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,632,964 параметров\n"
     ]
    }
   ],
   "source": [
    "class MusicGRU(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=256, hidden_dim=512, num_layers=3, dropout=0.3, pad_id=0):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.pad_id = pad_id\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_id)\n",
    "        \n",
    "        self.gru = nn.GRU(\n",
    "            embedding_dim,\n",
    "            hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc_out = nn.Linear(hidden_dim, vocab_size)\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        nn.init.xavier_uniform_(self.embedding.weight)\n",
    "        \n",
    "        for name, param in self.gru.named_parameters():\n",
    "            if 'weight_ih' in name:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "            elif 'bias' in name:\n",
    "                nn.init.zeros_(param)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.fc_out.weight)\n",
    "        nn.init.zeros_(self.fc_out.bias)\n",
    "    \n",
    "    def forward(self, x, hidden=None):\n",
    "        embedded = self.embedding(x)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        output = self.dropout(output)\n",
    "        \n",
    "        logits = self.fc_out(output)\n",
    "        \n",
    "        return logits, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size, device):\n",
    "        return torch.zeros(self.num_layers, batch_size, self.hidden_dim, device=device)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def generate(self, start_tokens, vocab, max_length=1000, temperature=1.0, top_k=None, top_p=None, device='cuda'):\n",
    "        self.eval()\n",
    "        \n",
    "        if isinstance(start_tokens, list):\n",
    "            tokens = torch.tensor([start_tokens], dtype=torch.long, device=device)\n",
    "        else:\n",
    "            tokens = start_tokens.unsqueeze(0) if start_tokens.dim() == 1 else start_tokens\n",
    "        \n",
    "        hidden = self.init_hidden(1, device)\n",
    "        \n",
    "        end_id = vocab.get(\"<end>\", None)\n",
    "        pad_id = vocab.get(\"<pad>\", self.pad_id)\n",
    "        \n",
    "        generated = tokens[0].tolist()\n",
    "        \n",
    "        for _ in range(max_length):\n",
    "            logits, hidden = self.forward(tokens, hidden)\n",
    "            next_token_logits = logits[0, -1, :] / temperature\n",
    "            next_token_logits[pad_id] = -float('inf')\n",
    "            \n",
    "            if top_k is not None:\n",
    "                indices_to_remove = next_token_logits < torch.topk(next_token_logits, top_k)[0][..., -1, None]\n",
    "                next_token_logits[indices_to_remove] = -float('inf')\n",
    "            \n",
    "            if top_p is not None:\n",
    "                sorted_logits, sorted_indices = torch.sort(next_token_logits, descending=True)\n",
    "                cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "                \n",
    "                sorted_indices_to_remove = cumulative_probs > top_p\n",
    "                sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "                sorted_indices_to_remove[..., 0] = 0\n",
    "                \n",
    "                indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
    "                next_token_logits[indices_to_remove] = -float('inf')\n",
    "            \n",
    "            probs = F.softmax(next_token_logits, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1)\n",
    "            \n",
    "            generated.append(next_token.item())\n",
    "            \n",
    "            if end_id is not None and next_token.item() == end_id:\n",
    "                break\n",
    "            \n",
    "            tokens = next_token.unsqueeze(0)\n",
    "        \n",
    "        return generated\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "model = MusicGRU(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=256,\n",
    "    hidden_dim=512,\n",
    "    num_layers=3,\n",
    "    dropout=0.3\n",
    ").to(device)\n",
    "    \n",
    "print(f\"{sum(p.numel() for p in model.parameters()):,} параметров\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "555d0d31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T14:44:47.231589Z",
     "iopub.status.busy": "2025-11-23T14:44:47.231360Z",
     "iopub.status.idle": "2025-11-23T14:57:22.966883Z",
     "shell.execute_reply": "2025-11-23T14:57:22.965976Z"
    },
    "papermill": {
     "duration": 755.740533,
     "end_time": "2025-11-23T14:57:22.968157",
     "exception": false,
     "start_time": "2025-11-23T14:44:47.227624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Эпоха 1/200\n",
      "Сохранена лучшая модель (val_loss: 4.6218)\n",
      "Время: 9.6s, LR: 0.000300\n",
      "Train Loss: 5.4184, Val Loss: 4.6218\n",
      "\n",
      "Эпоха 2/200\n",
      "Сохранена лучшая модель (val_loss: 4.3132)\n",
      "Время: 8.9s, LR: 0.000300\n",
      "Train Loss: 4.5676, Val Loss: 4.3132\n",
      "\n",
      "Эпоха 3/200\n",
      "Сохранена лучшая модель (val_loss: 4.1181)\n",
      "Время: 8.9s, LR: 0.000300\n",
      "Train Loss: 4.2925, Val Loss: 4.1181\n",
      "\n",
      "Эпоха 4/200\n",
      "Сохранена лучшая модель (val_loss: 3.9481)\n",
      "Время: 8.9s, LR: 0.000300\n",
      "Train Loss: 4.1028, Val Loss: 3.9481\n",
      "\n",
      "Эпоха 5/200\n",
      "Сохранена лучшая модель (val_loss: 3.8054)\n",
      "Время: 8.9s, LR: 0.000300\n",
      "Train Loss: 3.9457, Val Loss: 3.8054\n",
      "Сохранён чекпоинт эпохи 5\n",
      "\n",
      "Эпоха 6/200\n",
      "Сохранена лучшая модель (val_loss: 3.2743)\n",
      "Время: 8.9s, LR: 0.000300\n",
      "Train Loss: 3.6430, Val Loss: 3.2743\n",
      "\n",
      "Эпоха 7/200\n",
      "Сохранена лучшая модель (val_loss: 3.0013)\n",
      "Время: 8.9s, LR: 0.000300\n",
      "Train Loss: 3.1652, Val Loss: 3.0013\n",
      "\n",
      "Эпоха 8/200\n",
      "Сохранена лучшая модель (val_loss: 2.9051)\n",
      "Время: 8.9s, LR: 0.000300\n",
      "Train Loss: 2.9777, Val Loss: 2.9051\n",
      "\n",
      "Эпоха 9/200\n",
      "Сохранена лучшая модель (val_loss: 2.8434)\n",
      "Время: 8.9s, LR: 0.000300\n",
      "Train Loss: 2.8885, Val Loss: 2.8434\n",
      "\n",
      "Эпоха 10/200\n",
      "Сохранена лучшая модель (val_loss: 2.8125)\n",
      "Время: 8.9s, LR: 0.000300\n",
      "Train Loss: 2.8245, Val Loss: 2.8125\n",
      "Сохранён чекпоинт эпохи 10\n",
      "\n",
      "Эпоха 11/200\n",
      "Сохранена лучшая модель (val_loss: 2.7592)\n",
      "Время: 8.9s, LR: 0.000300\n",
      "Train Loss: 2.7672, Val Loss: 2.7592\n",
      "\n",
      "Эпоха 12/200\n",
      "Сохранена лучшая модель (val_loss: 2.7251)\n",
      "Время: 8.9s, LR: 0.000300\n",
      "Train Loss: 2.7156, Val Loss: 2.7251\n",
      "\n",
      "Эпоха 13/200\n",
      "Сохранена лучшая модель (val_loss: 2.6877)\n",
      "Время: 8.9s, LR: 0.000300\n",
      "Train Loss: 2.6722, Val Loss: 2.6877\n",
      "\n",
      "Эпоха 14/200\n",
      "Сохранена лучшая модель (val_loss: 2.6558)\n",
      "Время: 8.9s, LR: 0.000300\n",
      "Train Loss: 2.6302, Val Loss: 2.6558\n",
      "\n",
      "Эпоха 15/200\n",
      "Сохранена лучшая модель (val_loss: 2.6202)\n",
      "Время: 9.0s, LR: 0.000300\n",
      "Train Loss: 2.5927, Val Loss: 2.6202\n",
      "Сохранён чекпоинт эпохи 15\n",
      "\n",
      "Эпоха 16/200\n",
      "Сохранена лучшая модель (val_loss: 2.6058)\n",
      "Время: 8.9s, LR: 0.000300\n",
      "Train Loss: 2.5585, Val Loss: 2.6058\n",
      "\n",
      "Эпоха 17/200\n",
      "Сохранена лучшая модель (val_loss: 2.5758)\n",
      "Время: 9.0s, LR: 0.000300\n",
      "Train Loss: 2.5222, Val Loss: 2.5758\n",
      "\n",
      "Эпоха 18/200\n",
      "Сохранена лучшая модель (val_loss: 2.5439)\n",
      "Время: 9.0s, LR: 0.000300\n",
      "Train Loss: 2.4959, Val Loss: 2.5439\n",
      "\n",
      "Эпоха 19/200\n",
      "Сохранена лучшая модель (val_loss: 2.5350)\n",
      "Время: 9.0s, LR: 0.000300\n",
      "Train Loss: 2.4680, Val Loss: 2.5350\n",
      "\n",
      "Эпоха 20/200\n",
      "Сохранена лучшая модель (val_loss: 2.5127)\n",
      "Время: 9.0s, LR: 0.000300\n",
      "Train Loss: 2.4395, Val Loss: 2.5127\n",
      "Сохранён чекпоинт эпохи 20\n",
      "\n",
      "Эпоха 21/200\n",
      "Сохранена лучшая модель (val_loss: 2.5043)\n",
      "Время: 9.0s, LR: 0.000300\n",
      "Train Loss: 2.4173, Val Loss: 2.5043\n",
      "\n",
      "Эпоха 22/200\n",
      "Сохранена лучшая модель (val_loss: 2.4963)\n",
      "Время: 9.0s, LR: 0.000300\n",
      "Train Loss: 2.3907, Val Loss: 2.4963\n",
      "\n",
      "Эпоха 23/200\n",
      "Сохранена лучшая модель (val_loss: 2.4749)\n",
      "Время: 8.9s, LR: 0.000300\n",
      "Train Loss: 2.3676, Val Loss: 2.4749\n",
      "\n",
      "Эпоха 24/200\n",
      "Сохранена лучшая модель (val_loss: 2.4525)\n",
      "Время: 9.0s, LR: 0.000300\n",
      "Train Loss: 2.3440, Val Loss: 2.4525\n",
      "\n",
      "Эпоха 25/200\n",
      "Сохранена лучшая модель (val_loss: 2.4459)\n",
      "Время: 9.0s, LR: 0.000300\n",
      "Train Loss: 2.3229, Val Loss: 2.4459\n",
      "Сохранён чекпоинт эпохи 25\n",
      "\n",
      "Эпоха 26/200\n",
      "Сохранена лучшая модель (val_loss: 2.4290)\n",
      "Время: 9.0s, LR: 0.000300\n",
      "Train Loss: 2.3037, Val Loss: 2.4290\n",
      "\n",
      "Эпоха 27/200\n",
      "Сохранена лучшая модель (val_loss: 2.4273)\n",
      "Время: 9.0s, LR: 0.000300\n",
      "Train Loss: 2.2805, Val Loss: 2.4273\n",
      "\n",
      "Эпоха 28/200\n",
      "Сохранена лучшая модель (val_loss: 2.4092)\n",
      "Время: 9.0s, LR: 0.000300\n",
      "Train Loss: 2.2591, Val Loss: 2.4092\n",
      "\n",
      "Эпоха 29/200\n",
      "Сохранена лучшая модель (val_loss: 2.3975)\n",
      "Время: 9.0s, LR: 0.000300\n",
      "Train Loss: 2.2423, Val Loss: 2.3975\n",
      "\n",
      "Эпоха 30/200\n",
      "Сохранена лучшая модель (val_loss: 2.3830)\n",
      "Время: 9.0s, LR: 0.000300\n",
      "Train Loss: 2.2227, Val Loss: 2.3830\n",
      "Сохранён чекпоинт эпохи 30\n",
      "\n",
      "Эпоха 31/200\n",
      "Сохранена лучшая модель (val_loss: 2.3624)\n",
      "Время: 9.0s, LR: 0.000300\n",
      "Train Loss: 2.2048, Val Loss: 2.3624\n",
      "\n",
      "Эпоха 32/200\n",
      "Сохранена лучшая модель (val_loss: 2.3586)\n",
      "Время: 9.0s, LR: 0.000300\n",
      "Train Loss: 2.1856, Val Loss: 2.3586\n",
      "\n",
      "Эпоха 33/200\n",
      "Сохранена лучшая модель (val_loss: 2.3585)\n",
      "Время: 8.9s, LR: 0.000300\n",
      "Train Loss: 2.1707, Val Loss: 2.3585\n",
      "\n",
      "Эпоха 34/200\n",
      "Сохранена лучшая модель (val_loss: 2.3408)\n",
      "Время: 9.0s, LR: 0.000300\n",
      "Train Loss: 2.1549, Val Loss: 2.3408\n",
      "\n",
      "Эпоха 35/200\n",
      "Сохранена лучшая модель (val_loss: 2.3274)\n",
      "Время: 9.0s, LR: 0.000300\n",
      "Train Loss: 2.1389, Val Loss: 2.3274\n",
      "Сохранён чекпоинт эпохи 35\n",
      "\n",
      "Эпоха 36/200\n",
      "Сохранена лучшая модель (val_loss: 2.3265)\n",
      "Время: 9.0s, LR: 0.000300\n",
      "Train Loss: 2.1212, Val Loss: 2.3265\n",
      "\n",
      "Эпоха 37/200\n",
      "Сохранена лучшая модель (val_loss: 2.3075)\n",
      "Время: 9.0s, LR: 0.000300\n",
      "Train Loss: 2.1079, Val Loss: 2.3075\n",
      "\n",
      "Эпоха 38/200\n",
      "Время: 8.8s, LR: 0.000300\n",
      "Train Loss: 2.0911, Val Loss: 2.3085\n",
      "\n",
      "Эпоха 39/200\n",
      "Время: 8.9s, LR: 0.000300\n",
      "Train Loss: 2.0778, Val Loss: 2.3092\n",
      "\n",
      "Эпоха 40/200\n",
      "Сохранена лучшая модель (val_loss: 2.2945)\n",
      "Время: 9.0s, LR: 0.000300\n",
      "Train Loss: 2.0639, Val Loss: 2.2945\n",
      "Сохранён чекпоинт эпохи 40\n",
      "\n",
      "Эпоха 41/200\n",
      "Сохранена лучшая модель (val_loss: 2.2847)\n",
      "Время: 9.0s, LR: 0.000300\n",
      "Train Loss: 2.0513, Val Loss: 2.2847\n",
      "\n",
      "Эпоха 42/200\n",
      "Время: 8.8s, LR: 0.000300\n",
      "Train Loss: 2.0396, Val Loss: 2.2913\n",
      "\n",
      "Эпоха 43/200\n",
      "Время: 8.8s, LR: 0.000300\n",
      "Train Loss: 2.0233, Val Loss: 2.2917\n",
      "\n",
      "Эпоха 44/200\n",
      "Сохранена лучшая модель (val_loss: 2.2794)\n",
      "Время: 9.0s, LR: 0.000300\n",
      "Train Loss: 2.0133, Val Loss: 2.2794\n",
      "\n",
      "Эпоха 45/200\n",
      "Сохранена лучшая модель (val_loss: 2.2760)\n",
      "Время: 9.0s, LR: 0.000300\n",
      "Train Loss: 1.9977, Val Loss: 2.2760\n",
      "Сохранён чекпоинт эпохи 45\n",
      "\n",
      "Эпоха 46/200\n",
      "Сохранена лучшая модель (val_loss: 2.2730)\n",
      "Время: 9.0s, LR: 0.000300\n",
      "Train Loss: 1.9853, Val Loss: 2.2730\n",
      "\n",
      "Эпоха 47/200\n",
      "Сохранена лучшая модель (val_loss: 2.2562)\n",
      "Время: 9.0s, LR: 0.000300\n",
      "Train Loss: 1.9737, Val Loss: 2.2562\n",
      "\n",
      "Эпоха 48/200\n",
      "Сохранена лучшая модель (val_loss: 2.2550)\n",
      "Время: 9.0s, LR: 0.000300\n",
      "Train Loss: 1.9625, Val Loss: 2.2550\n",
      "\n",
      "Эпоха 49/200\n",
      "Сохранена лучшая модель (val_loss: 2.2416)\n",
      "Время: 9.0s, LR: 0.000300\n",
      "Train Loss: 1.9511, Val Loss: 2.2416\n",
      "\n",
      "Эпоха 50/200\n",
      "Время: 8.9s, LR: 0.000300\n",
      "Train Loss: 1.9407, Val Loss: 2.2522\n",
      "Сохранён чекпоинт эпохи 50\n",
      "\n",
      "Эпоха 51/200\n",
      "Время: 8.9s, LR: 0.000300\n",
      "Train Loss: 1.9289, Val Loss: 2.2423\n",
      "\n",
      "Эпоха 52/200\n",
      "Время: 8.9s, LR: 0.000300\n",
      "Train Loss: 1.9196, Val Loss: 2.2548\n",
      "\n",
      "Эпоха 53/200\n",
      "Время: 8.9s, LR: 0.000150\n",
      "Train Loss: 1.9056, Val Loss: 2.2472\n",
      "\n",
      "Эпоха 54/200\n",
      "Время: 8.9s, LR: 0.000150\n",
      "Train Loss: 1.8959, Val Loss: 2.2453\n",
      "\n",
      "Эпоха 55/200\n",
      "Сохранена лучшая модель (val_loss: 2.2353)\n",
      "Время: 9.0s, LR: 0.000150\n",
      "Train Loss: 1.8859, Val Loss: 2.2353\n",
      "Сохранён чекпоинт эпохи 55\n",
      "\n",
      "Эпоха 56/200\n",
      "Сохранена лучшая модель (val_loss: 2.2309)\n",
      "Время: 9.0s, LR: 0.000150\n",
      "Train Loss: 1.8823, Val Loss: 2.2309\n",
      "\n",
      "Эпоха 57/200\n",
      "Время: 8.9s, LR: 0.000150\n",
      "Train Loss: 1.8776, Val Loss: 2.2521\n",
      "\n",
      "Эпоха 58/200\n",
      "Время: 8.9s, LR: 0.000150\n",
      "Train Loss: 1.8689, Val Loss: 2.2546\n",
      "\n",
      "Эпоха 59/200\n",
      "Время: 8.9s, LR: 0.000150\n",
      "Train Loss: 1.8656, Val Loss: 2.2479\n",
      "\n",
      "Эпоха 60/200\n",
      "Время: 8.9s, LR: 0.000075\n",
      "Train Loss: 1.8576, Val Loss: 2.2369\n",
      "Сохранён чекпоинт эпохи 60\n",
      "\n",
      "Эпоха 61/200\n",
      "Время: 8.9s, LR: 0.000075\n",
      "Train Loss: 1.8526, Val Loss: 2.2469\n",
      "\n",
      "Эпоха 62/200\n",
      "Время: 8.9s, LR: 0.000075\n",
      "Train Loss: 1.8502, Val Loss: 2.2717\n",
      "\n",
      "Эпоха 63/200\n",
      "Время: 8.9s, LR: 0.000075\n",
      "Train Loss: 1.8477, Val Loss: 2.2540\n",
      "\n",
      "Эпоха 64/200\n",
      "Время: 8.9s, LR: 0.000037\n",
      "Train Loss: 1.8438, Val Loss: 2.2367\n",
      "\n",
      "Эпоха 65/200\n",
      "Время: 8.9s, LR: 0.000037\n",
      "Train Loss: 1.8407, Val Loss: 2.2451\n",
      "Сохранён чекпоинт эпохи 65\n",
      "\n",
      "Эпоха 66/200\n",
      "Время: 8.9s, LR: 0.000037\n",
      "Train Loss: 1.8407, Val Loss: 2.2444\n",
      "\n",
      "Эпоха 67/200\n",
      "Время: 8.9s, LR: 0.000037\n",
      "Train Loss: 1.8370, Val Loss: 2.2457\n",
      "\n",
      "Эпоха 68/200\n",
      "Время: 8.9s, LR: 0.000019\n",
      "Train Loss: 1.8358, Val Loss: 2.2448\n",
      "\n",
      "Эпоха 69/200\n",
      "Сохранена лучшая модель (val_loss: 2.2291)\n",
      "Время: 9.0s, LR: 0.000019\n",
      "Train Loss: 1.8345, Val Loss: 2.2291\n",
      "\n",
      "Эпоха 70/200\n",
      "Время: 8.9s, LR: 0.000019\n",
      "Train Loss: 1.8326, Val Loss: 2.2432\n",
      "Сохранён чекпоинт эпохи 70\n",
      "\n",
      "Эпоха 71/200\n",
      "Время: 8.9s, LR: 0.000019\n",
      "Train Loss: 1.8318, Val Loss: 2.2512\n",
      "\n",
      "Эпоха 72/200\n",
      "Время: 8.9s, LR: 0.000019\n",
      "Train Loss: 1.8320, Val Loss: 2.2425\n",
      "\n",
      "Эпоха 73/200\n",
      "Время: 8.9s, LR: 0.000009\n",
      "Train Loss: 1.8295, Val Loss: 2.2416\n",
      "\n",
      "Эпоха 74/200\n",
      "Время: 8.9s, LR: 0.000009\n",
      "Train Loss: 1.8292, Val Loss: 2.2457\n",
      "\n",
      "Эпоха 75/200\n",
      "Время: 8.9s, LR: 0.000009\n",
      "Train Loss: 1.8287, Val Loss: 2.2294\n",
      "Сохранён чекпоинт эпохи 75\n",
      "\n",
      "Эпоха 76/200\n",
      "Время: 8.9s, LR: 0.000009\n",
      "Train Loss: 1.8297, Val Loss: 2.2541\n",
      "\n",
      "Эпоха 77/200\n",
      "Время: 8.9s, LR: 0.000005\n",
      "Train Loss: 1.8297, Val Loss: 2.2369\n",
      "\n",
      "Эпоха 78/200\n",
      "Время: 8.9s, LR: 0.000005\n",
      "Train Loss: 1.8285, Val Loss: 2.2404\n",
      "\n",
      "Эпоха 79/200\n",
      "Время: 8.9s, LR: 0.000005\n",
      "Train Loss: 1.8272, Val Loss: 2.2428\n",
      "\n",
      "Эпоха 80/200\n",
      "Время: 8.9s, LR: 0.000005\n",
      "Train Loss: 1.8291, Val Loss: 2.2375\n",
      "Сохранён чекпоинт эпохи 80\n",
      "\n",
      "Эпоха 81/200\n",
      "Время: 8.9s, LR: 0.000002\n",
      "Train Loss: 1.8289, Val Loss: 2.2475\n",
      "\n",
      "Эпоха 82/200\n",
      "Время: 8.9s, LR: 0.000002\n",
      "Train Loss: 1.8255, Val Loss: 2.2377\n",
      "\n",
      "Эпоха 83/200\n",
      "Время: 8.9s, LR: 0.000002\n",
      "Train Loss: 1.8273, Val Loss: 2.2482\n",
      "\n",
      "Эпоха 84/200\n",
      "Время: 8.9s, LR: 0.000002\n",
      "Train Loss: 1.8268, Val Loss: 2.2461\n",
      "\n",
      "Early stopping после 84 эпох (patience=15)\n"
     ]
    }
   ],
   "source": [
    "def train_epoch(model, dataloader, optimizer, criterion, device, grad_clip=1.0, print_every=50):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_tokens = 0\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits, _ = model(inputs)\n",
    "        \n",
    "        logits_flat = logits.view(-1, logits.size(-1))\n",
    "        targets_flat = targets.view(-1)\n",
    "        \n",
    "        loss = criterion(logits_flat, targets_flat)\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        mask = targets_flat != model.pad_id\n",
    "        total_tokens += mask.sum().item()\n",
    "        \n",
    "        if (batch_idx + 1) % print_every == 0:\n",
    "            avg_loss = total_loss / (batch_idx + 1)\n",
    "            print(f\"  Batch {batch_idx + 1}/{len(dataloader)} | Loss: {avg_loss:.4f} | PPL: {np.exp(avg_loss):.2f}\")\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    \n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, dataloader, criterion, device, print_every=50):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        logits, _ = model(inputs)\n",
    "        \n",
    "        logits_flat = logits.view(-1, logits.size(-1))\n",
    "        targets_flat = targets.view(-1)\n",
    "        \n",
    "        loss = criterion(logits_flat, targets_flat)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if (batch_idx + 1) % print_every == 0:\n",
    "            print(f\"  Val Batch {batch_idx + 1}/{len(dataloader)} | Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    \n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader=None,\n",
    "    num_epochs=50,\n",
    "    learning_rate=0.001,\n",
    "    weight_decay=1e-5,\n",
    "    grad_clip=1.0,\n",
    "    device='cuda',\n",
    "    save_dir='checkpoints',\n",
    "    save_every=5,\n",
    "    patience=10,\n",
    "    print_every=50\n",
    "):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        betas=(0.9, 0.98),\n",
    "        eps=1e-9\n",
    "    )\n",
    "    \n",
    "    if val_loader is not None:\n",
    "        scheduler = ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='min',\n",
    "            factor=0.5,\n",
    "            patience=3,\n",
    "            verbose=True\n",
    "        )\n",
    "    else:\n",
    "        scheduler = CosineAnnealingLR(\n",
    "            optimizer,\n",
    "            T_max=num_epochs,\n",
    "            eta_min=learning_rate * 0.01\n",
    "        )\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=model.pad_id)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    epochs_without_improvement = 0\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        epoch_start = time.time()\n",
    "        \n",
    "        print(f\"\\nЭпоха {epoch}/{num_epochs}\")\n",
    "        \n",
    "        train_loss = train_epoch(model, train_loader, optimizer, criterion, device, grad_clip, print_every)\n",
    "        val_loss = validate(model, val_loader, criterion, device, print_every)\n",
    "        scheduler.step(val_loss)\n",
    "            \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_without_improvement = 0\n",
    "                \n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, os.path.join(save_dir, 'best_model.pt'))\n",
    "            print(f\"Сохранена лучшая модель (val_loss: {val_loss:.4f})\")\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start\n",
    "        \n",
    "        print(f\"Время: {epoch_time:.1f}s, LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "        \n",
    "        if epoch % save_every == 0:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'train_loss': train_loss,\n",
    "            }, os.path.join(save_dir, f'checkpoint_epoch_{epoch}.pt'))\n",
    "            print(f\"Сохранён чекпоинт эпохи {epoch}\")\n",
    "        \n",
    "        if val_loader is not None and epochs_without_improvement >= patience:\n",
    "            print(f\"\\nEarly stopping после {epoch} эпох (patience={patience})\")\n",
    "            break\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, os.path.join(save_dir, 'final_model.pt'))\n",
    "\n",
    "\n",
    "def load_checkpoint(model, checkpoint_path, optimizer=None):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    if optimizer is not None and 'optimizer_state_dict' in checkpoint:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    return checkpoint\n",
    "\n",
    "\n",
    "train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=200,\n",
    "    learning_rate=3e-4,\n",
    "    device=device,\n",
    "    save_dir='checkpoints',\n",
    "    save_every=5,\n",
    "    patience=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99489045",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T14:57:22.981566Z",
     "iopub.status.busy": "2025-11-23T14:57:22.981233Z",
     "iopub.status.idle": "2025-11-23T14:57:33.236764Z",
     "shell.execute_reply": "2025-11-23T14:57:33.235893Z"
    },
    "papermill": {
     "duration": 10.263672,
     "end_time": "2025-11-23T14:57:33.238140",
     "exception": false,
     "start_time": "2025-11-23T14:57:22.974468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    generated = model.generate(\n",
    "        start_tokens=[vocab[\"<start>\"]],\n",
    "        vocab=vocab,\n",
    "        max_length=1000,\n",
    "        temperature=0.9,\n",
    "        top_k=40,\n",
    "        top_p=0.95,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    tokens_to_midi(generated, vocab, \"generated\" + str(i) + \".mid\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 196294,
     "sourceId": 434491,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 803.146159,
   "end_time": "2025-11-23T14:57:34.664558",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-23T14:44:11.518399",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
