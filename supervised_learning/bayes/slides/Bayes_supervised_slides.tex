\documentclass[notheorems, handout]{beamer}

\usetheme{Warsaw}
\setbeamertemplate{page number in head/foot}[totalframenumber]
\setbeamertemplate{headline}{}
\setbeamertemplate{navigation symbols}{}
\usefonttheme[onlymath]{serif}

\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[russian]{babel}

\usepackage{graphicx,subcaption,ragged2e}
\usepackage{tikz}
\usepackage{bm}

\newtheorem{remark}{Замечание}

\title[Статистическое и машинное обучение]{Обучение с учителем. Байесовский подход}
\institute[Санкт-Петербургский Государственный Университет]{%
	\small
	Санкт-Петербургский государственный университет\\
	Кафедра статистического моделирования
}
\date{20 сентября 2025}
\newcommand{\vect}[1]{\mathbf{#1}}
\newcommand{\matr}[1]{\boldsymbol{#1}}
\begin{document}

\begin{frame}
	\titlepage
\end{frame}\begin{frame}
  \frametitle{Теорема Байеса: ядро подхода}
  \begin{block}{Фундаментальное правило обновления убеждений}
    В байесовском подходе параметры модели $\theta$ рассматриваются как случайные величины. Наши знания о них обновляются при поступлении данных $D$ с помощью теоремы Байеса.
  \end{block}
  \begin{equation*}
    \underbrace{p(\theta | D)}_{\text{Апостериор}} = \frac{\overbrace{p(D | \theta)}^{\text{Правдоподобие}} \cdot \overbrace{p(\theta)}^{\text{Априор}}}{\underbrace{p(D)}_{\text{Маргинальное правдоподобие}}}
  \end{equation*}
  \begin{itemize}
    \item \textbf{Априорное распределение $p(\theta)$}: наши убеждения о параметрах \textit{до} получения данных.
    \item \textbf{Правдоподобие $p(D | \theta)$}: вероятность наблюдать данные $D$ при фиксированных параметрах $\theta$.
    \item \textbf{Апостериорное распределение $p(\theta | D)$}: обновленные убеждения о $\theta$ \textit{после} учета данных.
  \end{itemize}
\end{frame}

\begin{frame}{Сравнение подходов: частотный и байесовский}
        \textbf{Частотный подход}
        \begin{itemize}
            \item Вероятность --- это долгосрочная частота события.
            \item Параметры модели ($\theta$) --- это фиксированные, неизвестные константы.
            \item Результат --- точечные оценки (например, ОМП) и доверительные интервалы.
            \item Доверительный интервал (например, 95\%) означает, что при многократном повторении эксперимента 95\% таких интервалов будут содержать истинное значение параметра.
        \end{itemize}
        \textbf{Байесовский подход}
        \begin{itemize}
            \item Вероятность --- это степень уверенности в утверждении.
            \item Параметры модели ($\theta$) --- это случайные величины с распределениями.
            \item Результат --- апостериорное распределение параметров.
            \item Доверительный интервал (например, 95\%) означает, что существует 95\%-ая вероятность того, что истинное значение параметра находится в этом интервале.
        \end{itemize}
\end{frame}

\begin{frame}{Пример: Линейная регрессия}
    \textbf{Частотная линейная регрессия:}
    \begin{itemize}
        \item Модель: $y = \vect{w}^T\vect{x} + \epsilon$, где $\epsilon \sim N(0, \sigma^2)$.
        \item Цель: найти точечные оценки коэффициентов $\beta$, которые минимизируют сумму квадратов ошибок.
        \item Результат: вектор коэффициентов $\hat{\beta}$ и их доверительные интервалы.
    \end{itemize}
    \vspace{0.5cm}
    \textbf{Байесовская линейная регрессия:}
    \begin{itemize}
        \item Модель та же, но на параметры $\vect{w}$ и $\sigma^2$ задаются априорные распределения, например, $\vect{w} \sim N(0, \alpha^{-1}I)$.
        \item Цель: найти апостериорные распределения для $\vect{w}$.
        \item Результат: полные распределения для каждого коэффициента, которые показывают нашу неуверенность в оценках.
    \end{itemize}
\end{frame}
\begin{frame}
  \frametitle{Математическая модель}
  Предполагаем, что шум аддитивный и гауссовский: $\epsilon \sim \mathcal{N}(0, \sigma^2)$.
  Тогда правдоподобие для одного объекта $(\vect{x}_i, y_i)$ имеет вид:
  $$ p(y_i|\vect{x}_i, \vect{w}) = \mathcal{N}(y_i | \vect{w}^T\vect{x}_i, \sigma^2) $$
  Для всей выборки $D = \{(\vect{x}_i, y_i)\}_{i=1}^N$: $p(D|\vect{w}) = \prod_i \mathcal{N}(y_i | \vect{w}^T\vect{x}_i, \sigma^2)$.
  
  \vspace{1em}
  \textbf{Априорное распределение}
  
  Чтобы избежать переобучения, вводим априорное распределение на веса $\vect{w}$. Обычно используется гауссовское распределение с центром в нуле:
  $$ p(\vect{w}) = \mathcal{N}(\vect{w} | \vect{0}, \alpha^{-1}\matr{I}) $$
  \begin{itemize}
    \item Параметр $\alpha$ контролирует "разброс" весов. Большое $\alpha$ "стягивает" веса к нулю.
    \item Это эквивалентно L2-регуляризации в частотном подходе.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Апостериорное распределение и предсказание}
  \begin{block}{Апостериорное распределение для весов}
    Так как априорное распределение и правдоподобие являются гауссовскими, то и апостериорное распределение $p(\vect{w}|D)$ тоже будет \textbf{гауссовским} (свойство сопряженности).
    $$ p(\vect{w}|D) \sim \mathcal{N}(\vect{w} | \vect{m}_N, \matr{S}_N) $$
    где $\vect{m}_N$ и $\matr{S}_N$ вычисляются на основе данных.
  \end{block}
  
    Для нового объекта $\vect{x}_*$ предсказание $y_*$ --- это не одно число, а целое распределение. Оно получается путем усреднения по всем возможным весам $\vect{w}$ с учетом их апостериорной вероятности:
    \[ p(y_*|\vect{x}_*, D) = \int p(y_*|\vect{x}_*, \vect{w}) p(\vect{w}|D) d\vect{w} \]
    Это распределение также является гауссовским. Его среднее --- это наше предсказание, а дисперсия --- мера нашей неуверенности в этом предсказании.
\end{frame}

\begin{frame}
  \frametitle{Байесовский подход к классификации} 
  \begin{block}{Подход}
    \begin{enumerate}
      \item \textbf{Моделирование}: Для каждого класса $k$ мы оцениваем плотность вероятности признаков $p(\vect{x}|y=k)$ и априорную вероятность класса $p(y=k)$.
      \item \textbf{Классификация}: Используем теорему Байеса для вычисления апостериорной вероятности:
      $$ p(y=k|\vect{x}) = \frac{p(\vect{x}|y=k) p(y=k)}{p(\vect{x})} $$
      И выбираем класс, который ее максимизирует.
    \end{enumerate}
  \end{block}
\end{frame}
\begin{frame}
  \frametitle{Наивный байесовский классификатор}
  \begin{block}{Ключевое ("наивное") предположение}
  Признаки $\vect{x} = (x_1, x_2, \dots, x_d)$ \textbf{условно независимы} при заданном классе $y=k$.
  \end{block}
  Математически это означает:
  $$ p(\vect{x}|y=k) = p(x_1, \dots, x_d|y=k) = \prod_{j=1}^{d} p(x_j|y=k) $$
  
  Это предположение резко упрощает задачу. Вместо оценки сложной многомерной плотности $p(\vect{x}|y=k)$, нам нужно оценить $d$ одномерных плотностей $p(x_j|y=k)$.
  
  \begin{block}{Правило классификации}
  $$ \hat{y} = \arg\max_k \left( \log p(y=k) + \sum_{j=1}^{d} \log p(x_j|y=k) \right) $$
  \end{block}
\end{frame}

\begin{frame}
  \frametitle{Вариации в зависимости от типа данных}
  Вид классификатора определяется выбором распределения для правдоподобия $p(x_j|y=k)$.
  
  \begin{columns}[T]
    \column{0.33\textwidth}
      \begin{block}{Gaussian NB}
        \textbf{Данные}: Непрерывные\\
        \textbf{Модель}: $p(x_j|y=k)$ --- нормальное распределение $\mathcal{N}(\mu_{jk}, \sigma_{jk}^2)$\\
        \textbf{Пример}: Классификация ирисов по длине и ширине лепестков
      \end{block}
      
    \column{0.33\textwidth}
      \begin{block}{Multinomial NB}
        \textbf{Данные}: Дискретные (счетчики)\\
        \textbf{Модель}: $p(x_j|y=k)$ --- мультиномиальное распределение\\
        \textbf{Пример}: Классификация текстов. $x_j$ --- частота $j$-го слова в документе
      \end{block}
      
    \column{0.33\textwidth}
      \begin{block}{Bernoulli NB}
        \textbf{Данные}: Бинарные (0/1)\\
        \textbf{Модель}: $p(x_j|y=k)$ --- распределение Бернулли\\
        \textbf{Пример}: Анализ спама. $x_j=1$, если $j$-е слово есть в письме, и $0$ иначе
      \end{block}
  \end{columns}
\end{frame}

\begin{frame}
    \frametitle{LDA и QDA}
    Дискриминантный анализ  решают задачу классификации, моделируя распределение данных для каждого класса.
    \begin{block}{Ключевое предположение}
     Плотность распределения признаков для каждого класса $k$ является многомерным нормальным распределением:
     $$ p(\vect{x}|y=k) \sim \mathcal{N}(\matr{\mu}_k, \matr{\Sigma}_k) $$
    \end{block}
    Для удобства вычислений переходим к логарифму апостериорной вероятности:
    $$ \hat{y} = \arg\max_k \left( \log p(\vect{x}|y=k) + \log p(y=k) \right) $$
    Подставляя логарифм плотности Гаусса, получаем дискриминантную функцию $\delta_k(\vect{x})$:
    $$ \delta_k(\vect{x}) = -\frac{1}{2}\log|\matr{\Sigma}_k| - \frac{1}{2}(\vect{x}-\matr{\mu}_k)^T\matr{\Sigma}_k^{-1}(\vect{x}-\matr{\mu}_k) + \log \pi_k $$
    где $\pi_k = p(y=k)$ --- априорная вероятность класса.
\end{frame}

\begin{frame}
  \frametitle{Квадратичный дискриминантный анализ (QDA)}
  \begin{block}{Предположение QDA}
    Каждый класс $k$ имеет собственную матрицу ковариаций $\matr{\Sigma}_k$.
  \end{block}
  
  Дискриминантная функция $\delta_k(\vect{x})$ является квадратичной функцией от $\vect{x}$:
  $$ \delta_k(\vect{x}) = -\frac{1}{2}\vect{x}^T\matr{\Sigma}_k^{-1}\vect{x} + \vect{x}^T\matr{\Sigma}_k^{-1}\matr{\mu}_k - \frac{1}{2}\matr{\mu}_k^T\matr{\Sigma}_k^{-1}\matr{\mu}_k -\frac{1}{2}\log|\matr{\Sigma}_k| + \log \pi_k $$
  \begin{itemize}
    \item Условие $\delta_k(\vect{x}) = \delta_j(\vect{x})$ задает квадратичную разделяющую поверхность (эллипсоид, параболоид, гиперболоид).
    \item QDA --- очень гибкий метод, но требует оценки большого числа параметров для каждой матрицы $\matr{\Sigma}_k$, что может привести к переобучению на малых выборках.
  \end{itemize}
\end{frame}

% --- Слайд: LDA ---
\begin{frame}
  \frametitle{Линейный дискриминантный анализ (LDA)}
  \begin{block}{Предположение LDA}
    Все классы имеют общую матрицу ковариаций $\matr{\Sigma}_k = \matr{\Sigma}$.
  \end{block}
  
  Это упрощение сильно меняет дискриминантную функцию. Член $\vect{x}^T\matr{\Sigma}^{-1}\vect{x}$ становится одинаковым для всех классов и не влияет на $\arg\max_k$.
  
  \begin{block}{Линейная дискриминантная функция}
    $$ \delta_k(\vect{x}) = \vect{x}^T\matr{\Sigma}^{-1}\matr{\mu}_k - \frac{1}{2}\matr{\mu}_k^T\matr{\Sigma}^{-1}\matr{\mu}_k + \log\pi_k $$
  \end{block}
  \begin{itemize}
    \item Это линейная функция от $\vect{x}$.
    \item Разделяющая поверхность $\delta_k(\vect{x}) = \delta_j(\vect{x})$ является гиперплоскостью.
    \item LDA более устойчив к переобучению, чем QDA, так как оценивается меньше параметров.
  \end{itemize}
\end{frame}
\begin{frame}
  \frametitle{Визуализация разделяющих поверхностей}
  \begin{figure}
    \includegraphics[width=\textwidth]{img/lda_vs_qda.pdf}
    \caption{Слева: LDA создает линейные границы. Справа: QDA создает гибкие квадратичные границы, которые лучше разделяют классы с разной формой ковариации.}
  \end{figure}
\end{frame}

\begin{frame}{Вычисление апостериорного распределения}
    Для вычисления апостериорного распределения $p(\theta|D) \propto p(D|\theta)p(\theta)$ необходимо вычислить знаменатель (маргинальное правдоподобие):
    \begin{equation*}
        P(D) = \int P(D | \theta) P(\theta) d\theta
    \end{equation*}
    \begin{itemize}
        \item Этот интеграл часто является неразрешимым аналитически, особенно в моделях с большим числом параметров.
        \item Существует два основных подхода к решению этой проблемы:
        \begin{enumerate}
            \item Аналитический вывод с использованием сопряженных априорных распределений.
            \item Численные методы, такие как методы Монте-Карло по схеме марковских цепей (MCMC).
        \end{enumerate}
    \end{itemize}
\end{frame}

\begin{frame}{Аналитический подход: Сопряженные распределения}
    \begin{itemize}
        \item \textbf{Определение:} Априорное распределение $P(\theta)$ называется сопряженным для функции правдоподобия $P(D|\theta)$, если получаемое апостериорное распределение $P(\theta|D)$ принадлежит тому же семейству распределений, что и априорное.
        \item \textbf{Преимущество:} Это позволяет вывести параметры апостериорного распределения аналитически, без необходимости численного интегрирования.
    \end{itemize}
    \vspace{0.5cm}
    \textbf{Пример:}
    \begin{itemize}
        \item \textbf{Правдоподобие (Биномиальное):} Моделируем $k$ успехов в $n$ испытаниях с вероятностью успеха $\theta$.
        \begin{equation*}
            P(D|\theta) = \text{Bin}(k|n, \theta) \propto \theta^k (1-\theta)^{n-k}
        \end{equation*}
        \item \textbf{Априорное (Бета):} Предполагаем, что $\theta$ следует Бета-распределению.
        \begin{equation*}
            P(\theta) = \text{Beta}(\theta|\alpha, \beta) \propto \theta^{\alpha-1} (1-\theta)^{\beta-1}
        \end{equation*}
        \item \textbf{Апостериорное (Бета):} Апостериорное распределение также является Бета-распределением.
        \begin{equation*}
            P(\theta|D) \propto \theta^{k+\alpha-1} (1-\theta)^{n-k+\beta-1} = \text{Beta}(\theta|k+\alpha, n-k+\beta)
        \end{equation*}
    \end{itemize}
\end{frame}

\begin{frame}{Численный подход: Методы MCMC}
    \begin{itemize}
        \item \textbf{Идея:} Если мы не можем аналитически описать апостериорное распределение, мы можем сгенерировать из него выборку.
        \item MCMC (Markov Chain Monte Carlo) --- это алгоритм, строящий марковскую цепь, стационарное распределение которой совпадает с искомым апостериорным распределением $p(\theta|D)$.
         \item Использование сопряженных априорных распределений удобно, но часто является сильным упрощением.
        \item Мы хотим использовать более гибкие или более реалистичные априорные распределения, которые не являются сопряженными.
        \item Модель сложна, и найти сопряженное распределение для всех параметров невозможно.
    \end{itemize}
    \vspace{0.5cm}
\end{frame}

\begin{frame}{Численный подход: Методы MCMC}
    \textbf{Пример:}
    \begin{enumerate}
        \item Начинаем со случайного значения параметра $\theta_0$.
        \item На каждой итерации $t$:
        \begin{itemize}
            \item Предлагаем нового кандидата $\theta'$ из некоторого предложенного распределения $q(\theta'|\theta_{t-1})$.
            \item Вычисляем коэффициент принятия $\alpha = \frac{p(\theta'|D)}{p(\theta_{t-1}|D)}$. Так как $p(\theta|D) \propto p(D|\theta)p(\theta)$, нам не нужно знать нормализующую константу.
            \item Принимаем кандидата ($\theta_t = \theta'$) с вероятностью $\min(1, \alpha)$, иначе оставляем старое значение ($\theta_t = \theta_{t-1}$).
        \end{itemize}
        \item После достаточного числа итераций полученные значения $\{\theta_t\}$ будут выборкой из апостериорного распределения.
    \end{enumerate}
\end{frame}


\end{document}