{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip -qq install evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T14:38:42.886939Z","iopub.execute_input":"2025-11-30T14:38:42.887124Z","iopub.status.idle":"2025-11-30T14:38:51.096588Z","shell.execute_reply.started":"2025-11-30T14:38:42.887108Z","shell.execute_reply":"2025-11-30T14:38:51.095855Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nfrom transformers import (\n    BertTokenizer,\n    BertForSequenceClassification,\n    Trainer,\n    TrainingArguments,\n    TrainerCallback,\n    EvalPrediction\n)\nimport evaluate\nimport torch\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, auc\n\nimport random\nimport os\nimport re\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T14:38:51.097883Z","iopub.execute_input":"2025-11-30T14:38:51.098159Z","iopub.status.idle":"2025-11-30T14:39:23.628869Z","shell.execute_reply.started":"2025-11-30T14:38:51.098117Z","shell.execute_reply":"2025-11-30T14:39:23.628222Z"}},"outputs":[{"name":"stderr","text":"2025-11-30 14:39:04.480135: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764513544.661600      91 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764513544.714277      91 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"file_path = \"/kaggle/input/phishingemails/Phishing_Email.csv\"\ndf_raw = pd.read_csv(file_path, index_col=0).rename(columns={\"Email Text\": \"body\", \"Email Type\": \"label_text\"})\ndf_raw[\"label\"] = (df_raw[\"label_text\"] != \"Safe Email\").astype(int)\n\ndf_raw.describe(exclude=int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T14:39:23.630725Z","iopub.execute_input":"2025-11-30T14:39:23.631480Z","iopub.status.idle":"2025-11-30T14:39:25.013929Z","shell.execute_reply.started":"2025-11-30T14:39:23.631460Z","shell.execute_reply":"2025-11-30T14:39:25.013268Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"         body  label_text\ncount   18634       18650\nunique  17537           2\ntop     empty  Safe Email\nfreq      533       11322","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>body</th>\n      <th>label_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>18634</td>\n      <td>18650</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>17537</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>empty</td>\n      <td>Safe Email</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>533</td>\n      <td>11322</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"df = df_raw[df_raw[\"body\"] != \"empty\"].dropna(subset=\"body\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T14:39:25.014627Z","iopub.execute_input":"2025-11-30T14:39:25.014811Z","iopub.status.idle":"2025-11-30T14:39:25.025993Z","shell.execute_reply.started":"2025-11-30T14:39:25.014796Z","shell.execute_reply":"2025-11-30T14:39:25.025397Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"print(\"Safe Email:\\n\")\nprint(df[(df[\"label\"] == 0) & (df[\"body\"].map(len) < 100)].iloc[0, 0])\nprint(\"\\nPhishing Email:\\n\")\nprint(df[(df[\"label\"] == 1) & (df[\"body\"].map(len) < 100)].iloc[0, 0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T14:39:25.026797Z","iopub.execute_input":"2025-11-30T14:39:25.027132Z","iopub.status.idle":"2025-11-30T14:39:25.045692Z","shell.execute_reply.started":"2025-11-30T14:39:25.027110Z","shell.execute_reply":"2025-11-30T14:39:25.044953Z"}},"outputs":[{"name":"stdout","text":"Safe Email:\n\nhpl nom for august 15 , 2000 ( see attached file : hplo 815 . xls ) - hplo 815 . xls\n\nPhishing Email:\n\nre [ 11 ] bands leonardo di caprio in 1939 ? ? ? ? ? ? shania twain french hospitals\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## Classes and Functionsclass ","metadata":{}},{"cell_type":"code","source":"class SpecialDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = {key: val if torch.is_tensor(val) else torch.tensor(val) for key, val in encodings.items()}\n        self.labels = labels if torch.is_tensor(labels) else torch.tensor(labels)\n\n    def __getitem__(self, idx):\n        item = {key: val[idx] for key, val in self.encodings.items()}\n        item['labels'] = self.labels[idx]\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\n    def to(self, device):\n        self.encodings = {key: val.to(device) for key, val in self.encodings.items()}\n        self.labels = self.labels.to(device)\n        return self \n    \n    \ndef text_cleaner(text):\n    text = text.lower()\n    \n    # Replace URLs with _url_\n    text = re.sub(r'https?://\\S+|www\\.\\S+', '_url_', text)\n    \n    # Replace emails with _email_\n    text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', '_email_', text)\n    \n    # Remove special characters except ', \", _url_, and _email_\n    text = re.sub(r\"[^a-zA-Z0-9\\s'\\\"_]\", '', text)\n    \n    # Remove sequences of underscores that are not _url_ or _email_\n    def clean_underscores(match):\n        text = match.group(0)\n        if text in ['_url_', '_email_']:\n            return text\n        return text.replace('_', '')\n\n    text = re.sub(r'\\b_[a-zA-Z0-9_]*_\\b', clean_underscores, text)\n    \n    # Replace sequences of whitespace with a single space\n    text = re.sub(r'\\s+', ' ', text)\n    \n    # Strip leading and trailing whitespace\n    text = text.strip()\n    \n    return text\n\ndef get_texts_labels(df: pd.DataFrame):\n    texts = df[\"body\"].apply(text_cleaner).tolist()\n    labels = df[\"label\"].tolist()\n    \n    return texts, labels\n\ndef split_data(texts: list[str], labels: list[str], seed=42):\n    train_texts, val_test_texts, train_labels, val_test_labels = train_test_split(\n        texts, labels, test_size=0.2, random_state=seed, stratify=labels)\n\n    val_texts, test_texts, val_labels, test_labels = train_test_split(\n        val_test_texts, val_test_labels, test_size=0.5, random_state=seed, stratify=val_test_labels)\n    return train_texts, val_texts, test_texts, train_labels, val_labels, test_labels\n\n\ndef encode_texts(texts: list[str],\n                 tokenizer: BertTokenizer,\n                 max_length: int = 512):\n    encodings = tokenizer(texts, truncation=True, padding=True, max_length=max_length, return_tensors='pt')\n    return encodings\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndef get_datasets(texts: list[str],\n                 labels: list[str],\n                 tokenizer_dir: str = '/kaggle/input/huggingface-bert/bert-base-uncased',\n                 save: bool = False,\n                 move: bool = False):\n    global device\n    \n    tokenizer = BertTokenizer.from_pretrained(tokenizer_dir)\n\n    train_texts, val_texts, test_texts, train_labels, val_labels, test_labels = split_data(texts, labels)\n\n    train_encodings = encode_texts(train_texts, tokenizer)\n    val_encodings = encode_texts(val_texts, tokenizer)\n    test_encodings = encode_texts(test_texts, tokenizer)\n    \n    train_dset = SpecialDataset(train_encodings, train_labels)\n    val_dset = SpecialDataset(val_encodings, val_labels)\n    test_dset = SpecialDataset(test_encodings, test_labels)\n    \n    if move:\n        train_dset = train_dset.to(device)\n        val_dset = val_dset.to(device)\n        test_dset = test_dset.to(device)\n    if save:\n        tokenizer.save_pretrained('/kaggle/working/tokenizer_save')\n    \n    return train_dset, val_dset, test_dset\n\naccuracy_metric = evaluate.load(\"accuracy\")\nroc_auc_metric = evaluate.load(\"roc_auc\")\n\ndef compute_metrics(p: EvalPrediction):\n    global accuracy_metric\n    global roc_auc_metric\n    preds = np.argmax(p.predictions, axis=1)\n    \n    accuracy_result = accuracy_metric.compute(predictions=preds, references=p.label_ids)\n    \n    if p.predictions.shape[1] == 2:\n        probs = p.predictions[:, 1]\n        roc_auc_result = roc_auc_metric.compute(prediction_scores=probs, references=p.label_ids)\n    else:\n        roc_auc_result = roc_auc_metric.compute(prediction_scores=p.predictions, references=p.label_ids, multi_class='ovr')\n\n    return {\n        \"accuracy\": accuracy_result[\"accuracy\"],\n        \"roc_auc\": roc_auc_result[\"roc_auc\"]\n    }\n\ndef print_trainable_parameters(model):\n    trainable_params = 0\n    all_param = 0\n    for _, param in model.named_parameters():\n        all_param += param.numel()\n        if param.requires_grad:\n            trainable_params += param.numel()\n    print(\n        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}\"\n    )\n    \ndef freeze_parameters(model, predicate):\n    for name, param in model.named_parameters():\n        if predicate(name, param):\n          param.requires_grad = False\n\ndef unfreeze_parameters(model, predicate):\n    for name, param in model.named_parameters():\n        if predicate(name, param):\n          param.requires_grad = True\n\ndef predicate(name, param):\n    return not (name.startswith(\"bert.pooler.dense\") or name.startswith(\"classifier\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T14:51:20.787739Z","iopub.execute_input":"2025-11-30T14:51:20.788039Z","iopub.status.idle":"2025-11-30T14:51:22.018402Z","shell.execute_reply.started":"2025-11-30T14:51:20.788018Z","shell.execute_reply":"2025-11-30T14:51:22.017794Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"## Creating Datasets","metadata":{}},{"cell_type":"code","source":"model_path = '/kaggle/input/phishing-email-classifier-bert/transformers/scam-email-classifier-bert-uncased'\ntokenizer_path = '/kaggle/input/phishing-email-classifier-bert/transformers/scam-email-bert-tokenizer'\ndsets_dir = '/kaggle/input/phishing-email-classifier-bert/phishing-email-encoded-datasets'\nmodel = BertForSequenceClassification.from_pretrained(model_path)\ntokenizer = BertTokenizer.from_pretrained(tokenizer_path)\n\ntexts, labels = get_texts_labels(df)\nprint('Creating datasets...')\ntrain_dset, val_dset, test_dset = get_datasets(texts, labels, tokenizer_path, move=True)\nprint('Datasets created')\n\nprint(f'Train size: {len(train_dset)}')\nprint(f'Validation size: {len(val_dset)}')\nprint(f'Test size: {len(test_dset)}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T14:40:04.447198Z","iopub.execute_input":"2025-11-30T14:40:04.447795Z","iopub.status.idle":"2025-11-30T14:42:16.791663Z","shell.execute_reply.started":"2025-11-30T14:40:04.447768Z","shell.execute_reply":"2025-11-30T14:42:16.790859Z"}},"outputs":[{"name":"stdout","text":"Creating datasets...\nDatasets created\nTrain size: 14480\nValidation size: 1810\nTest size: 1811\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"## Using Pre-Trained Model","metadata":{}},{"cell_type":"code","source":"os.environ[\"WANDB_DISABLED\"] = \"true\"\n\ntraining_args = TrainingArguments(\n    output_dir=\"/kaggle/working/\",\n    eval_strategy=\"epoch\",\n    dataloader_pin_memory=not torch.cuda.is_available(),\n    \n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dset,\n    eval_dataset=val_dset,\n    compute_metrics=compute_metrics\n)\n\nresults = trainer.predict(test_dset)\nmetrics = results.metrics\n\nprint(\"Pre-Trained Evaluation Metrics:\\n  \")\nprint(\"\\n  \".join([f\"{key}: {val}\" for key, val in metrics.items()]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T14:44:20.147776Z","iopub.execute_input":"2025-11-30T14:44:20.148535Z","iopub.status.idle":"2025-11-30T14:44:46.714035Z","shell.execute_reply.started":"2025-11-30T14:44:20.148507Z","shell.execute_reply":"2025-11-30T14:44:46.713435Z"}},"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Pre-Trained Evaluation Metrics:\n  \ntest_loss: 0.05169203504920006\n  test_model_preparation_time: 0.0029\n  test_accuracy: 0.9906129210381005\n  test_roc_auc: 0.9984881718270916\n  test_runtime: 26.5199\n  test_samples_per_second: 68.288\n  test_steps_per_second: 8.56\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## Fine-Tuning model","metadata":{}},{"cell_type":"code","source":"unfreeze_parameters(model, predicate)\nprint_trainable_parameters(model)\nfreeze_parameters(model, predicate)\nprint_trainable_parameters(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T14:51:32.956459Z","iopub.execute_input":"2025-11-30T14:51:32.957074Z","iopub.status.idle":"2025-11-30T14:51:32.963401Z","shell.execute_reply.started":"2025-11-30T14:51:32.957051Z","shell.execute_reply":"2025-11-30T14:51:32.962574Z"}},"outputs":[{"name":"stdout","text":"trainable params: 109483778 || all params: 109483778 || trainable%: 100.00\ntrainable params: 592130 || all params: 109483778 || trainable%: 0.54\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T14:51:41.943117Z","iopub.execute_input":"2025-11-30T14:51:41.943646Z","iopub.status.idle":"2025-11-30T15:04:45.174012Z","shell.execute_reply.started":"2025-11-30T14:51:41.943622Z","shell.execute_reply":"2025-11-30T15:04:45.173377Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5430' max='5430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5430/5430 13:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Model Preparation Time</th>\n      <th>Accuracy</th>\n      <th>Roc Auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.042800</td>\n      <td>0.040264</td>\n      <td>0.002900</td>\n      <td>0.990055</td>\n      <td>0.999380</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.031100</td>\n      <td>0.045112</td>\n      <td>0.002900</td>\n      <td>0.990055</td>\n      <td>0.999382</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.041500</td>\n      <td>0.040755</td>\n      <td>0.002900</td>\n      <td>0.990608</td>\n      <td>0.999382</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=5430, training_loss=0.04239851581018494, metrics={'train_runtime': 782.8143, 'train_samples_per_second': 55.492, 'train_steps_per_second': 6.937, 'total_flos': 1.14295442448384e+16, 'train_loss': 0.04239851581018494, 'epoch': 3.0})"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"results = trainer.predict(test_dset)\nmetrics = results.metrics\n\nprint(\"Fine-Tuned Evaluation Metrics:\\n  \")\nprint(\"\\n  \".join([f\"{key}: {val}\" for key, val in metrics.items()]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T15:11:33.137342Z","iopub.execute_input":"2025-11-30T15:11:33.138124Z","iopub.status.idle":"2025-11-30T15:11:59.689392Z","shell.execute_reply.started":"2025-11-30T15:11:33.138096Z","shell.execute_reply":"2025-11-30T15:11:59.688684Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Fine-Tuned Evaluation Metrics:\n  \ntest_loss: 0.03856932371854782\n  test_model_preparation_time: 0.0029\n  test_accuracy: 0.9911651021535064\n  test_roc_auc: 0.9985106980025076\n  test_runtime: 26.5403\n  test_samples_per_second: 68.236\n  test_steps_per_second: 8.553\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"| Metric | Before  | After   |\n| ------ | ------- | ------- |\n| Loss   | 0.051   | 0.039   |\n| Acc    | 0.9906  | 0.9912  |\n| ROC-AUC| 0.99849 | 0.99851 |","metadata":{}},{"cell_type":"markdown","source":"## ROC-Curve plot and some test dataset examples","metadata":{}},{"cell_type":"code","source":"preds = np.apply_along_axis(np.argmax, 1, results.predictions)\ntrue_label_0_indices = [i for i, label in enumerate(test_dset.labels.cpu()) if label == 0 and preds[i] == 1]\ntrue_label_1_indices = [i for i, label in enumerate(test_dset.labels.cpu()) if label == 1 and preds[i] == 0]\n\nsample_indices_0 = random.sample(true_label_0_indices, 1)\nsample_indices_1 = random.sample(true_label_1_indices, 1)\n\nsample_indices = sample_indices_0 + sample_indices_1\n\nfor idx in sample_indices:\n    email_encoding = {key: val[idx].unsqueeze(0) for key, val in test_dset.encodings.items()}\n    input_ids = email_encoding['input_ids']\n    email_text = tokenizer.decode(input_ids[0], skip_special_tokens=True)\n    true_label = test_dset.labels[idx].item()\n    predicted_label = np.argmax(results.predictions[idx])\n\n    print(f\"Email: {email_text}\")\n    print(f\"True Label: {true_label}, Predicted Label: {predicted_label}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T15:28:02.712419Z","iopub.execute_input":"2025-11-30T15:28:02.713006Z","iopub.status.idle":"2025-11-30T15:28:02.760890Z","shell.execute_reply.started":"2025-11-30T15:28:02.712977Z","shell.execute_reply":"2025-11-30T15:28:02.760249Z"}},"outputs":[{"name":"stdout","text":"Email: cnet shopper newsletter desktops notebooks editionshopper all cnet the web 1 canon powershot s40 2 canon powershot g2 3 gateway 600xl 4 dell latitude c400 5 cyber shot dscf707 all most popular atlas micro gs 9800 pentium 4 253 ghz 512mb ddr sdram 40gb hard drive cdrwdvdrom 19inch crt nvidia geforce4 ti 4200 just 2099peripherals for your desktop canon s900 photo printerwacom intuis2 6x8 tabletwireless keyboard mouse viewsonic viewpanel vp 181gateway 600xl pentium 4m 18ghz 256mb ram 40gb hard drive 157inch tft active matrix starting at 2899 dell dimension 4000 pentium 4 17ghz to 253ghz 128mb to 1gb up to 120gb hard drive starting at 739 dell inspiron 2600 series 1ghz to 17ghz 128mb to 256mb ram 20gb to 40gb hard drive just 999 hp pavilion n5450 pentium iii 850mhz 128mb ram 20gb hard drive 15inch tft active matrix just 1099 gateway solo 1450se intel celeron 12ghz 128mb ram 20gb hard drive 141inch tft active matrix just 1158 did you know that channelonline's storesite enables you to set up a private storefront with your company name and logo in less than an houryour customers can view quotes you have created for them search the product database build their own quotes based on the pricing you've predetermined for them and place orders with you online 247sign up now to give your customers a whole new level of servicetell me more about channelonline tech trends hardware software shopping downloads news investing electronics web building help howtos internet games message boards cnet tv radio music centerthe email address for your subscription is _ email _ unsubscribe change email format change email address faq advertiseprice comparisons product reviews tech news downloads all cnet services copyright 2002 cnet networks inc all rights reserved\nTrue Label: 0, Predicted Label: 1\n\nEmail: re 8 talk thread about our tabs spu m r th ewe an saf twa ph macy en st dthe es yof ar inc eyo xualdes spe umeby reas urse ireand rmvol 500 100 uraland deeff incon ttowel wnbra nat nosi ects tras l kno nds expe cethr eslon gas rien eetim geror ms wor deshi gwit hou ldwi ppin hin 24 rs ph acy is ne st the est y of arm inc e yo xual des spe ume by reas ur se ire and rm vol 500 100 ural and de eff in con t to wel wn bra nat no si ects tras l kno nds expe ce thr es lon gas rien ee tim ger or ms wor de shi g wit hou ld wi ppin hin 24 rs sp m ur the we and saf wa ph acy is ne st the est y of arm inc e yo xual des spe ume by reas ur se ire and rm vol 500 100 ural and de eff in con t to wel wn bra nat no si ects tras l kno nds expe ce thr es lon gas rien ee tim ger or ms wor de shi g wit hou ld wi ppin hin 24 rs sp m ur the we and saf wa ph acy is ne st the est y of arm inc e yo xual des spe ume by reas ur se ire and rm vol 500 100 ural and de eff in con t to wel wn bra nat no si ects tras l kno nds expe ce thr es lon gas rien ee tim ger or ms wor de shi g wit hou ld wi ppin hin 24 rs sp m ur the we and saf wa ph acy is ne st the est y of arm inc e yo xual des spe ume by reas ur se ire and rm vol 500 100 ural and de eff in con t to wel wn bra nat no si ects tras l kno nds expe ce thr es lon gas rien ee tim ger or ms wor de shi g wit hou ld wi ppin hin 24 rs\nTrue Label: 1, Predicted Label: 0\n\n","output_type":"stream"}],"execution_count":36}]}